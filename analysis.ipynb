{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificando o dataset MNIST usando MLPs e CNNs\n",
    "\n",
    "### Membros\n",
    "\n",
    "* Gabriel Pessoa\n",
    "* Ícaro Guerra\n",
    "* Lucas Barros\n",
    "* Matheus Pessoa\n",
    "* Rafael Mota\n",
    "\n",
    "## Introdução\n",
    "Esse relatório detalha o processo experimental para o desenvolvimento de uma solução para o problema de classificação de dígitos escritos manualmente do dataset MNIST usando Redes Neurais dos tipos: Multilayer Perceptron (MLP) e Convolutional Neural Network (CNN). O dataset MNIST consiste em 70 mil imagens 28x28 dos dígitos de 0 a 9, sendo 60 mil samples de treinamento e 10 mil samples de teste.\n",
    "\n",
    "## Bibliotecas Utilizadas\n",
    "Para a implementação utilzaremos as seguintes bibliotecas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-11 14:05:08.819268: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2021-07-11 14:05:08.819296: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O Numpy e o Pandas são usados para a representação dos dados e para a implementação de funções auxiliares.\n",
    "\n",
    "* Tensorflow e Keras são usados para a implementação e treinamento das Redes Neurais.\n",
    "\n",
    "## Carregamento dos Dados\n",
    "O código a seguir carrega os dados do dataset, adapta ao formato desejado e define os parâmetros globais sobre os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n60000 train samples\n10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros de Treinamento\n",
    "Aqui definimos os parâmetro de treinamento que serão utilizados para todas as redes neurais, a escolha dessa quantidade de epochs e batch_size, foi feita para que tenhamos maior perfomance e mais dinamicidade no experimento com os treinamentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-11 14:05:13.500922: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2021-07-11 14:05:13.500957: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n2021-07-11 14:05:13.501023: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LARANJAL-016153): /proc/driver/nvidia/version does not exist\n2021-07-11 14:05:13.501358: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "verbose = 0\n",
    "\n",
    "metrics = [\"accuracy\", keras.metrics.Precision(), keras.metrics.Recall()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Avaliação\n",
    "Aqui definimos a duas funções que vamos usar para avaliar as soluções, a primeira função `accuracy_per_class` retorna a métrica de *acurácia* para cada uma das classes de resposta, que no nosso caso são os possíveis dígitos de 0 a 9. A segunda função `accuracy_precision_recall` retorna as métricas *acurácia*, *precision* e *recall* total.\n",
    "\n",
    "Um breve descrição das métricas citadas seria:\n",
    "\n",
    "* *acurácia*: A proporção de predição corretas com o total de casos.\n",
    "* *precision*: A proporção de predições positivas corretas com o total de predições positivas da classe.\n",
    "* *recall*: A proporção de predições positivas corretas com o total de casos da classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(model):\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    correct = [0] * num_classes\n",
    "    total = [0] * num_classes\n",
    "\n",
    "    for real, pred in zip(y_test.argmax(axis=1), y_pred.argmax(axis=1)):\n",
    "        if real == pred:\n",
    "            correct[real] += 1\n",
    "        total[real] += 1\n",
    "\n",
    "    accuracies = []\n",
    "    for correct, total in zip(correct, total):\n",
    "        accuracies.append(correct / total)\n",
    "\n",
    "    return pd.Series(data=accuracies, index=range(0,num_classes), name=\"Accuracy per class\")\n",
    "\n",
    "def accuracy_precision_recall(model):\n",
    "    _, acc, prec, rec = model.evaluate(x_test, y_test,verbose=0)\n",
    "\n",
    "    return pd.Series(data=[acc, prec, rec],index=[\"Accuracy\", \"Precision\", \"Recall\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentação\n",
    "\n",
    "A seguir começaremos a fase de experimentação, testando diferentes modelos de Redes Neurais e de aprendizado, para achar uma solução para o problema de classificação do dataset MNIST.\n",
    "\n",
    "\n",
    "### MLP 1\n",
    "Primeiramente, vamos usar uma rede neural MLP simples, com uma camada de entrada com um neuron para cada um dos pixels da imagem, uma camada oculta com 50 neurons, e uma camada de saída com ativação softmax, com um neuron para cada possível saída, no nosso caso 10. Essa estrutura vai se repetir em futuras redes, podendo variar os parâmetros de aprendizado e os parâmetros e a estrutura das camadas ocultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(50),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(), metrics=metrics)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8925697d90>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.981633\n",
       "1    0.978855\n",
       "2    0.890504\n",
       "3    0.907921\n",
       "4    0.929735\n",
       "5    0.867713\n",
       "6    0.948852\n",
       "7    0.922179\n",
       "8    0.877823\n",
       "9    0.894945\n",
       "Name: Accuracy per class, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_per_class(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o primeiro modelo obtemos o seguinte resultado, um rede neural simples já acerta grande parte dos casos do Dataset, mas podemos melhorar isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy     0.921100\n",
       "Precision    0.938185\n",
       "Recall       0.907600\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_precision_recall(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2\n",
    "A seguir verificamos o impacto de aumentar a quantidade de neurons na mesma Layer, conservando os demais parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 400)               314000    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                4010      \n",
      "=================================================================\n",
      "Total params: 318,010\n",
      "Trainable params: 318,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(400),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model2.compile(loss=\"categorical_crossentropy\", optimizer=SGD(), metrics=metrics)\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f892539df70>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse caso podemos verificar que houve um pequeno ganho de desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy     0.92260\n",
       "Precision    0.93994\n",
       "Recall       0.90770\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_precision_recall(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3\n",
    "Podemos tentar também adicionar mais uma camada oculta de Neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(300),\n",
    "    layers.Dense(100),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model2.compile(loss=\"categorical_crossentropy\", optimizer=SGD(), metrics=metrics)\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f89547f7d60>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que houve um pequeno ganho de perfomance, e que o processo de treinamento e predição ficaram bem mais lentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy     0.924200\n",
       "Precision    0.938123\n",
       "Recall       0.912700\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_precision_recall(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4\n",
    "Outro parâmetro que podemos variar é a função de ativação, o default para a biblioteca é a função linear, que não é muito recomendada para problemas, não linearmente separáveis. Vamos verificar com o a função sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 400)               314000    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                4010      \n",
      "=================================================================\n",
      "Total params: 318,010\n",
      "Trainable params: 318,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = keras.Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(400, activation=\"sigmoid\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model3.compile(loss=\"categorical_crossentropy\", optimizer=SGD(), metrics=metrics)\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f89545d1460>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando a função de ativação sigmoid houve uma piora no desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy     0.914100\n",
       "Precision    0.939669\n",
       "Recall       0.890900\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_precision_recall(model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5\n",
    "Vamos testar agora com a função de ativação ReLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_9 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 400)               314000    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                4010      \n",
      "=================================================================\n",
      "Total params: 318,010\n",
      "Trainable params: 318,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = keras.Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(400, activation=\"relu\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model4.compile(loss=\"categorical_crossentropy\", optimizer=SGD(), metrics=metrics)\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8950c7ea30>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a função de ativação ReLU houve uma melhora considerável em relação às execução usando outras funções de ativação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy     0.958300\n",
       "Precision    0.968482\n",
       "Recall       0.949500\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_precision_recall(model4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6\n",
    "Agora, podemos tentar adicionar uma nova camada na rede, dessa vez usando a função de ativação ReLU:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_10 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 400)               314000    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 437,310\n",
      "Trainable params: 437,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = keras.Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(400, activation=\"relu\"),\n",
    "    layers.Dense(300, activation=\"relu\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model5.compile(loss=\"categorical_crossentropy\", optimizer=SGD(), metrics=metrics)\n",
    "\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f89501f57c0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O tempo para treinamento e predição aumentou mas houve um melhora considerável na acurácia da rede usando 2 camadas de neurons com a função de ativação ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy     0.971000\n",
       "Precision    0.975856\n",
       "Recall       0.966000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_precision_recall(model5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7\n",
    "\n",
    "Em seguida, podemos testar variar a taxa de aprendizado, o valor padrão para esse parâmetro na biblioteca Keras é 0.01, vamos experimentar aumentar esse valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 400)               314000    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 437,310\n",
      "Trainable params: 437,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6 = keras.Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(400, activation=\"relu\"),\n",
    "    layers.Dense(300, activation=\"relu\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model6.compile(loss=\"categorical_crossentropy\", optimizer=SGD(0.2), metrics=metrics)\n",
    "\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7d5037b4f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtemos uma melhora em relação ao resultado anterior, isso provavelmente acontece por estarmos executando com uma quantidade limitada de épocas, fazendo com que uma taxa de ativação maior faça a rede neural convergir mais rápidamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy     0.983100\n",
       "Precision    0.983684\n",
       "Recall       0.982700\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_precision_recall(model6)"
   ]
  },
  {
   "source": [
    "### MLP 8\n",
    "\n",
    "Podemos também usar uma técnica de regularização chamada de Dropout, que no processo de treinamento \"ignora\" uma porcentagem dos neurons a cada iteração. Essa técnica tem como objetivo distribuir o \"trabalho\" de reconhecimento das classes entre diversos Neurons, o que pode ajudar a reduzir o overfitting. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 400)               314000    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 437,310\n",
      "Trainable params: 437,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model7 = keras.Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(400, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(300, activation=\"relu\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model7.compile(loss=\"categorical_crossentropy\", optimizer=SGD(0.2), metrics=metrics)\n",
    "\n",
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-11 14:05:44.010606: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n2021-07-11 14:05:44.012315: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2299965000 Hz\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdde1e65c10>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model7.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=verbose)"
   ]
  },
  {
   "source": [
    "Obtemos uma melhora no desempenho ao usar essa técnica."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Accuracy     0.986100\n",
       "Precision    0.987174\n",
       "Recall       0.985200\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "accuracy_precision_recall(model7)"
   ]
  },
  {
   "source": [
    "### MLP 9\n",
    "\n",
    "Podemos também tentar mudar o algoritmo de treinamento, um possível algoritmo é o Adam:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 400)               314000    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 437,310\n",
      "Trainable params: 437,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model8 = keras.Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(400, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(300, activation=\"relu\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model8.compile(loss=\"categorical_crossentropy\", optimizer=Adam(0.2), metrics=metrics)\n",
    "\n",
    "model8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fddd4122970>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "model8.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=verbose)"
   ]
  },
  {
   "source": [
    "Analisando os resultados, podemos deduzir que o algoritmo Adam não funciona com learning rates altos para esse conjunto de dados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Accuracy     0.0982\n",
       "Precision    0.0000\n",
       "Recall       0.0000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "accuracy_precision_recall(model8)"
   ]
  },
  {
   "source": [
    "### MLP 10\n",
    "\n",
    "Tentamos em seguida executar o com o algoritmo de aprendizado Adam com a learning rate default."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 400)               314000    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 437,310\n",
      "Trainable params: 437,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model9 = keras.Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(400, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(300, activation=\"relu\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model9.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=metrics)\n",
    "\n",
    "model9.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fddd413bf40>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "model9.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Accuracy     0.986400\n",
       "Precision    0.986793\n",
       "Recall       0.986300\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "accuracy_precision_recall(model9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                54090     \n",
      "=================================================================\n",
      "Total params: 54,410\n",
      "Trainable params: 54,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model10 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model10.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=metrics)\n",
    "\n",
    "model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "422/422 [==============================] - 19s 41ms/step - loss: 0.3573 - accuracy: 0.9024 - precision: 0.9615 - recall: 0.8932 - val_loss: 0.1361 - val_accuracy: 0.9638 - val_precision: 0.9738 - val_recall: 0.9553\n",
      "Epoch 2/50\n",
      "304/422 [====================>.........] - ETA: 4s - loss: 0.1336 - accuracy: 0.9613 - precision: 0.9705 - recall: 0.9542"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12094/3370938264.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model10.fit(x_train, y_train, batch_size=batch_size, epochs=10, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_precision_recall(model10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "828347deea3abc4070f76cfb51056c59301b7e5e4ab6780ef22839cb4d850b58"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}