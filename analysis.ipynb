{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificando o dataset MNIST usando MLPs e CNNs\n",
    "\n",
    "### Membros\n",
    "\n",
    "* Gabriel Pessoa\n",
    "* Ícaro Guerra\n",
    "* Lucas Barros\n",
    "* Matheus Pessoa\n",
    "* Rafael Mota\n",
    "\n",
    "## Introdução\n",
    "Esse relatório detalha o processo experimental para o desenvolvimento de uma solução para o problema de classificação de dígitos escritos manualmente do dataset MNIST usando Redes Neurais dos tipos: Multilayer Perceptron (MLP) e Convolutional Neural Network (CNN). O dataset MNIST consiste em 70 mil imagens 28x28 dos dígitos de 0 a 9, sendo 60 mil samples de treinamento e 10 mil samples de teste.\n",
    "\n",
    "## Bibliotecas Utilizadas\n",
    "Para a implementação utilzaremos as seguintes bibliotecas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-09 16:33:37.016303: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2021-07-09 16:33:37.016373: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O Numpy e o Pandas são usados para a representação dos dados e para a implementação de funções auxiliares.\n",
    "\n",
    "* Tensorflow e Keras são usados para a implementação e treinamento das Redes Neurais.\n",
    "\n",
    "## Carregamento dos Dados\n",
    "O código a seguir carrega os dados do dataset, adapta ao formato desejado e define os parâmetros globais sobre os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n60000 train samples\n10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros de Treinamento\n",
    "Aqui definimos os parâmetro de treinamento que serão utilizados para todas as redes neurais, a escolha dessa quantidade de epochs e batch_size, foi feita para que tenhamos maior perfomance e mais dinamicidade no experimento com os treinamentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-09 16:33:44.904151: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2021-07-09 16:33:44.904214: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n2021-07-09 16:33:44.904372: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LARANJAL-016153): /proc/driver/nvidia/version does not exist\n2021-07-09 16:33:44.905103: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "verbose = 0\n",
    "\n",
    "metrics = [\"accuracy\", keras.metrics.Precision(), keras.metrics.Recall()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Avaliação\n",
    "Aqui definimos a duas funções que vamos usar para avaliar as soluções, a primeira função `accuracy_per_class` retorna a métrica de *acurácia* para cada uma das classes de resposta, que no nosso caso são os possíveis dígitos de 0 a 9. A segunda função `accuracy_precision_recall` retorna as métricas *acurácia*, *precision* e *recall* total.\n",
    "\n",
    "Um breve descrição das métricas citadas seria:\n",
    "\n",
    "* *acurácia*: A proporção de predição corretas com o total de casos.\n",
    "* *precision*: A proporção de predições positivas corretas com o total de predições positivas da classe.\n",
    "* *recall*: A proporção de predições positivas corretas com o total de casos da classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(model):\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    correct = [0] * num_classes\n",
    "    total = [0] * num_classes\n",
    "\n",
    "    for real, pred in zip(y_test.argmax(axis=1), y_pred.argmax(axis=1)):\n",
    "        if real == pred:\n",
    "            correct[real] += 1\n",
    "        total[real] += 1\n",
    "\n",
    "    accuracies = []\n",
    "    for correct, total in zip(correct, total):\n",
    "        accuracies.append(correct / total)\n",
    "\n",
    "    return pd.Series(data=accuracies, index=range(0,num_classes), name=\"Accuracy per class\")\n",
    "\n",
    "def accuracy_precision_recall(model):\n",
    "    _, acc, prec, rec = model.evaluate(x_test, y_test,verbose=0)\n",
    "\n",
    "    return pd.Series(data=[acc, prec, rec],index=[\"Accuracy\", \"Precision\", \"Recall\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentação\n",
    "\n",
    "A seguir começaremos a fase de experimentação, testando diferentes modelos de Redes Neurais e de aprendizado, para achar uma solução para o problema de classificação do dataset MNIST.\n",
    "\n",
    "\n",
    "### MLP 1\n",
    "Primeiramente, vamos usar uma rede neural MLP simples, com uma camada de entrada com um neuron para cada um dos pixels da imagem, uma camada oculta com 50 neurons, e uma camada de saída com ativação softmax, com um neuron para cada possível saída, no nosso caso 10. Essa estrutura vai se repetir em futuras redes, podendo variar os parâmetros de aprendizado e os parâmetros e a estrutura das camadas ocultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(50),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(), metrics=metrics)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8925697d90>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.981633\n",
       "1    0.978855\n",
       "2    0.890504\n",
       "3    0.907921\n",
       "4    0.929735\n",
       "5    0.867713\n",
       "6    0.948852\n",
       "7    0.922179\n",
       "8    0.877823\n",
       "9    0.894945\n",
       "Name: Accuracy per class, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_per_class(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o primeiro modelo obtemos o seguinte resultado, um rede neural simples já acerta grande parte dos casos do Dataset, mas podemos melhorar isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy     0.921100\n",
       "Precision    0.938185\n",
       "Recall       0.907600\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_precision_recall(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 2\n",
    "A seguir verificamos o impacto de aumentar a quantidade de neurons na mesma Layer, conservando os demais parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 400)               314000    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                4010      \n",
      "=================================================================\n",
      "Total params: 318,010\n",
      "Trainable params: 318,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(400),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model2.compile(loss=\"categorical_crossentropy\", optimizer=SGD(), metrics=metrics)\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f892539df70>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse caso podemos verificar que houve um pequeno ganho de desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy     0.92260\n",
       "Precision    0.93994\n",
       "Recall       0.90770\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_precision_recall(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 3\n",
    "Podemos tentar também adicionar mais uma camada oculta de Neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(300),\n",
    "    layers.Dense(100),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model2.compile(loss=\"categorical_crossentropy\", optimizer=SGD(), metrics=metrics)\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f89547f7d60>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que houve um pequeno ganho de perfomance, e que o processo de treinamento e predição ficaram bem mais lentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy     0.924200\n",
       "Precision    0.938123\n",
       "Recall       0.912700\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_precision_recall(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 4\n",
    "Outro parâmetro que podemos variar é a função de ativação, o default para a biblioteca é a função linear, que não é muito recomendada para problemas, não linearmente separáveis. Vamos verificar com o a função sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 400)               314000    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                4010      \n",
      "=================================================================\n",
      "Total params: 318,010\n",
      "Trainable params: 318,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = keras.Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(400, activation=\"sigmoid\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model3.compile(loss=\"categorical_crossentropy\", optimizer=SGD(), metrics=metrics)\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f89545d1460>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando a função de ativação sigmoid houve uma piora no desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy     0.914100\n",
       "Precision    0.939669\n",
       "Recall       0.890900\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_precision_recall(model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5\n",
    "Vamos testar agora com a função de ativação ReLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_9 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 400)               314000    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                4010      \n",
      "=================================================================\n",
      "Total params: 318,010\n",
      "Trainable params: 318,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = keras.Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(400, activation=\"relu\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model4.compile(loss=\"categorical_crossentropy\", optimizer=SGD(), metrics=metrics)\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8950c7ea30>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a função de ativação ReLU houve uma melhora considerável em relação às execução usando outras funções de ativação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy     0.958300\n",
       "Precision    0.968482\n",
       "Recall       0.949500\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_precision_recall(model4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 6\n",
    "Agora, podemos tentar adicionar uma nova camada na rede, dessa vez usando a função de ativação ReLU:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_10 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 400)               314000    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 437,310\n",
      "Trainable params: 437,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = keras.Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(400, activation=\"relu\"),\n",
    "    layers.Dense(300, activation=\"relu\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model5.compile(loss=\"categorical_crossentropy\", optimizer=SGD(), metrics=metrics)\n",
    "\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f89501f57c0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O tempo para treinamento e predição aumentou mas houve um melhora considerável na acurácia da rede usando 2 camadas de neurons com a função de ativação ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy     0.971000\n",
       "Precision    0.975856\n",
       "Recall       0.966000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_precision_recall(model5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 7\n",
    "\n",
    "Em seguida, podemos testar variar a taxa de aprendizado, o valor padrão para esse parâmetro na biblioteca Keras é 0.01, vamos experimentar aumentar esse valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 400)               314000    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 437,310\n",
      "Trainable params: 437,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6 = keras.Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(400, activation=\"relu\"),\n",
    "    layers.Dense(300, activation=\"relu\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model6.compile(loss=\"categorical_crossentropy\", optimizer=SGD(0.2), metrics=metrics)\n",
    "\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7d5037b4f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtemos uma melhora em relação ao resultado anterior, isso provavelmente acontece por estarmos executando com uma quantidade limitada de épocas, fazendo com que uma taxa de ativação maior faça a rede neural convergir mais rápidamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy     0.983100\n",
       "Precision    0.983684\n",
       "Recall       0.982700\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_precision_recall(model6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndropout_4 (Dropout)          (None, 28, 28, 1)         0         \n_________________________________________________________________\nflatten_4 (Flatten)          (None, 784)               0         \n_________________________________________________________________\ndense_12 (Dense)             (None, 400)               314000    \n_________________________________________________________________\ndense_13 (Dense)             (None, 300)               120300    \n_________________________________________________________________\ndense_14 (Dense)             (None, 10)                3010      \n=================================================================\nTotal params: 437,310\nTrainable params: 437,310\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model7 = keras.Sequential([\n",
    "    layers.Dropout(0.3, input_shape=input_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(400, activation=\"relu\"),\n",
    "    layers.Dense(300, activation=\"relu\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model7.compile(loss=\"categorical_crossentropy\", optimizer=SGD(0.2), metrics=metrics)\n",
    "\n",
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe88cf7b940>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "model7.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Accuracy     0.986500\n",
       "Precision    0.987385\n",
       "Recall       0.986200\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "accuracy_precision_recall(model7)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "828347deea3abc4070f76cfb51056c59301b7e5e4ab6780ef22839cb4d850b58"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}